# Preface

<span class="marginnote">Initial draft posted 2014 Summer.  Recent updates (2016) include major overhaul from pdf to web-based presentation (twice!). The last pdf version I made is [here](http://m-clark.github.io/docs/IntroBayes.pdf) if anyone wants it, however, it will no longer be updated.  You can download the auto-generated (and ugly) pdf for this document [here](https://m-clark.github.io/docs/bayesian/basics/Bayesian_Basics.pdf).</span>
The following serves as a practical and applied introduction to Bayesian estimation methods for the uninitiated. The goal is to provide just enough information in a brief format to allow one to feel comfortable exploring Bayesian data analysis for themselves, assuming they have the requisite context to begin with. The idea is to cover a similar amount of material as one would in part of a standard statistics sequence in various applied disciplines where statistics is being introduced in general.  

After a conceptual introduction, a fully visible by-hand example is provided using the binomial distribution.  After that, the document proceeds to introduce fully Bayesian analysis with the standard linear regression model, as that is the basis for most applied statistics courses and is assumed to be most familiar to the reader.  Model diagnostics, model enhancements, and additional modeling issues are then explored.  Supplemental materials provide more technical detail if desired, and include a maximum likelihood refresher, overview of programming options in Bayesian analysis, the same regression model using BUGS and JAGS, and 'by-hand' code for the model using the Metropolis-Hastings and Hamiltonian Monte Carlo algorithms.


## Prerequisites

Prerequisites include a basic statistical exposure such as what would be covered in typical (probably graduate) *applied* science statistics course. At least some familiarity with R is necessary to follow the code, but that itself is not necessary, and one may go through any number of introductions on the web to acquire enough knowledge in that respect.  However, note that for the examples here, at least part of the code will employ some Bayesian-specific programming language (e.g. Stan primarily, BUGS and JAGS in the appendix).  No attempt is made to teach those languages though, as it would be difficult to do so efficiently in this more conceptually oriented setting.  As such, it is suggested that one follow the code as best they can, and investigate the respective manuals, relevant texts, etc. further on their own.  Between the text and comments within the code it is hoped that what the code is accomplishing will be fairly clear.  However, I also provide a set of notes that can serve as an overview of Stan [here](https://m-clark.github.io/workshops/bayesian/).

This document relies heavily on @gelman_bda, which I highly recommend, if one is ready for it.  Other sources used or particularly pertinent to the material in this document can be found in the [references section](#references) at the end. Some are more introductory, and which might be more suitable depending on the context you bring.



Color coding:

- <span class="emph">emphasis</span>
- <span class="pack">package</span>
- <span class="func">function</span>
- <span class="objclass">object/class</span>
- [link][Prerequisites]
