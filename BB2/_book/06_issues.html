<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="Bayesian Basics" />
<meta property="og:type" content="book" />


<meta property="og:description" content="An introduction to Bayesian data analysis." />
<meta name="github-repo" content="m-clark/Workshops" />


<meta name="date" content="2016-11-25" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="An introduction to Bayesian data analysis.">

<title>Bayesian Basics</title>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />
<link rel="stylesheet" href="..\css\tufte_bookdown\mytufte.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#home"><span style="color:transparent">Home</span></a></li>
<li class="has-sub"><a href="00_preface.html#preface">Preface</a><ul>
<li><a href="00_preface.html#prerequisites">Prerequisites</a></li>
</ul></li>
<li class="has-sub"><a href="01_intro.html#introduction">Introduction</a><ul>
<li class="has-sub"><a href="01_intro.html#bayesian-probability">Bayesian Probability</a><ul>
<li><a href="01_intro.html#conditional-probability-bayes-theorem">Conditional probability &amp; Bayes theorem</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="02_example.html#a-hands-on-example">A Hands-on Example</a><ul>
<li><a href="02_example.html#prior-likelihood-posterior-distributions">Prior, likelihood, &amp; posterior distributions</a></li>
<li><a href="02_example.html#prior">Prior</a></li>
<li><a href="02_example.html#likelihood">Likelihood</a></li>
<li><a href="02_example.html#posterior">Posterior</a></li>
<li><a href="02_example.html#posterior-predictive">Posterior predictive</a></li>
</ul></li>
<li class="has-sub"><a href="03_models.html#regression-models">Regression Models</a><ul>
<li><a href="03_models.html#example-linear-regression-model">Example: Linear Regression Model</a></li>
<li class="has-sub"><a href="03_models.html#setup">Setup</a><ul>
<li><a href="03_models.html#stan-code">Stan Code</a></li>
<li><a href="03_models.html#running-the-model">Running the Model</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="04_diagnostics.html#model-checking-diagnostics">Model Checking &amp; Diagnostics</a><ul>
<li class="has-sub"><a href="04_diagnostics.html#monitoring-convergence">Monitoring Convergence</a><ul>
<li><a href="04_diagnostics.html#visual-inspection-traceplot-densities">Visual Inspection: Traceplot &amp; Densities</a></li>
<li><a href="04_diagnostics.html#statistical-measures">Statistical Measures</a></li>
<li><a href="04_diagnostics.html#autocorrelation">Autocorrelation</a></li>
</ul></li>
<li class="has-sub"><a href="04_diagnostics.html#model-checking">Model Checking</a><ul>
<li><a href="04_diagnostics.html#sensitivity-analysis">Sensitivity Analysis</a></li>
<li><a href="04_diagnostics.html#predictive-accuracy-model-comparison">Predictive Accuracy &amp; Model Comparison</a></li>
<li><a href="04_diagnostics.html#posterior-predictive-checking-statistical">Posterior Predictive Checking: Statistical</a></li>
<li><a href="04_diagnostics.html#posterior-predictive-checking-graphical">Posterior Predictive Checking: Graphical</a></li>
</ul></li>
<li><a href="04_diagnostics.html#summary">Summary</a></li>
</ul></li>
<li class="has-sub"><a href="05_enhancements.html#model-enhancements">Model Enhancements</a><ul>
<li><a href="05_enhancements.html#generating-new-variables-of-interest">Generating New Variables of Interest</a></li>
<li><a href="05_enhancements.html#robust-regression">Robust Regression</a></li>
<li><a href="05_enhancements.html#generalized-linear-model">Generalized Linear Model</a></li>
</ul></li>
<li class="has-sub"><a href="06_issues.html#issues">Issues</a><ul>
<li><a href="06_issues.html#debugging">Debugging</a></li>
<li class="has-sub"><a href="06_issues.html#choice-of-prior">Choice of Prior</a><ul>
<li><a href="06_issues.html#noninformative-weakly-informative-informative">Noninformative, Weakly Informative, Informative</a></li>
<li><a href="06_issues.html#conjugacy">Conjugacy</a></li>
<li><a href="06_issues.html#sensitivity-analysis-revisited">Sensitivity Analysis Revisited</a></li>
<li><a href="06_issues.html#summary-1">Summary</a></li>
</ul></li>
<li class="has-sub"><a href="06_issues.html#sampling-procedure">Sampling Procedure</a><ul>
<li><a href="06_issues.html#metropolis">Metropolis</a></li>
<li><a href="06_issues.html#gibbs">Gibbs</a></li>
<li><a href="06_issues.html#hamiltonian-monte-carlo">Hamiltonian Monte Carlo</a></li>
<li><a href="06_issues.html#other-variations-and-approximate-methods">Other Variations and Approximate Methods</a></li>
</ul></li>
<li><a href="06_issues.html#number-of-draws-thinning-warm-up">Number of draws, thinning, warm-up</a></li>
<li><a href="06_issues.html#model-complexity">Model Complexity</a></li>
</ul></li>
<li><a href="1000_Conclusion.html#summary-2">Summary</a></li>
<li class="has-sub"><a href="1001_Appendix.html#appendix">Appendix</a><ul>
<li class="has-sub"><a href="1001_Appendix.html#maximum-likelihood-review">Maximum Likelihood Review</a><ul>
<li><a href="1001_Appendix.html#example">Example</a></li>
</ul></li>
<li><a href="1001_Appendix.html#linear-model">Linear Model</a></li>
<li><a href="1001_Appendix.html#binomial-likelihood-example">Binomial Likelihood Example</a></li>
<li class="has-sub"><a href="1001_Appendix.html#modeling-languages">Modeling Languages</a><ul>
<li><a href="1001_Appendix.html#bugs">Bugs</a></li>
<li><a href="1001_Appendix.html#jags">JAGS</a></li>
<li><a href="1001_Appendix.html#stan">Stan</a></li>
<li><a href="1001_Appendix.html#r">R</a></li>
<li><a href="1001_Appendix.html#general-statistical-packages">General Statistical Packages</a></li>
<li><a href="1001_Appendix.html#other-programming-languages">Other Programming Languages</a></li>
<li><a href="1001_Appendix.html#summary-3">Summary</a></li>
</ul></li>
<li><a href="1001_Appendix.html#bugs-example">BUGS Example</a></li>
<li><a href="1001_Appendix.html#jags-example">JAGS Example</a></li>
<li><a href="1001_Appendix.html#metropolis-hastings-example">Metropolis Hastings Example</a></li>
<li><a href="1001_Appendix.html#hamiltonian-monte-carlo-example">Hamiltonian Monte Carlo Example</a></li>
</ul></li>
<li><a href="1002_references.html#references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="issues" class="section level1">
<h1>Issues</h1>
<p>This section highlights some things to think about, as well as questions that would naturally arise for the applied researcher who might now be ready to start in on their first Bayesian analysis. It provides merely a taste regarding some select issues, and at this point one should be consulting Bayesian analysis texts directly.</p>
<div id="debugging" class="section level2">
<h2>Debugging</h2>
<p>An essential part of Bayesian analysis is debugging to see if your code and model are doing what it should be doing<label for="tufte-sn-28" class="margin-toggle sidenote-number">28</label><input type="checkbox" id="tufte-sn-28" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">28</span> It really should be a part of most analysis.</span>, and this especially holds for more complex models. For many models and common settings for the number of simulations, Bayesian analysis can still take several minutes on standard computers or laptops. With big data and/or complex models, some might take hours or even <em>days</em>. In either case, it is a waste of time to let broken code/models run unnecessarily.</p>
<p>The idea with debugging is that, once you think you have everything set up the way you like, run very short attempts to see if A, the code even compiles, and B, whether it runs appropriately. As such, you will only want to set your warm-up and iterations to some small number to begin with, e.g. maybe not even 100 iterations, and no more than two chains<label for="tufte-sn-29" class="margin-toggle sidenote-number">29</label><input type="checkbox" id="tufte-sn-29" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">29</span> With Stan I sometimes do a 1 iteration compile check first.</span>. Sometimes it will be obvious what a problem is, such as a typo resulting in the program of choice not being able to locate the parameter of interest. Others may be fairly subtle, for example, when it comes to prior specification.</p>
<p>Along with shorter runs, one should consider simpler models first, and perhaps using only a subset of the data. Especially for complex models, it helps to build the model up, debugging and checking for problems along the way. As a not too complicated example, consider a mixed model for logistic regression. One could even start with a standard linear model ignoring the binary nature of the target. Getting a sense of things from that and just making sure that inputs etc. are in place, one can supply the inverse logit link and change the sampling distribution to Bernoulli. Now you can think about adding the random effect, other explanatory variables of interest, and any other complexities that had not been included yet.</p>
<p>As you identify issues, you fix any problems that arise and tinker with other settings. Once you are satisfied, <em>then</em> try for the big run. Even then, you might spot new issues with a longer chain, so you can rinse and repeat at that point. BUGS, JAGS, and Stan more or less have this capacity built in with model upgrade functions. For example, in Stan you can feed the previous setup of a model in to the main <span class="func">stan</span> function. Use one for your initial runs, then when you’re ready, supply the model object as input to the ‘fit’ argument, perhaps with adjustments to the Monte Carlo settings.</p>
</div>
<div id="choice-of-prior" class="section level2">
<h2>Choice of Prior</h2>
<p>Selection of prior distributions might be a bit daunting for the new user of applied Bayesian analysis, but in many cases, and especially for standard models, there are more or less widely adopted choices. Even so, we will discuss the options from a general point of view.</p>
<div id="noninformative-weakly-informative-informative" class="section level3">
<h3>Noninformative, Weakly Informative, Informative</h3>
<p>We can begin with <span class="emph">noninformative priors</span> , which might also be referred to as <em>vague</em>, <em>flat</em>, <em>reference</em>, <em>objective</em>, or <em>diffuse</em>. The idea is to use something that allows for Bayesian inference but puts all the premium on the data, and/or soi-disant <em>objectivity</em>. As we have alluded to elsewhere, if we put a prior uniform distribution on the regression coefficients (and e.g. the log of <span class="math inline">\(\sigma\)</span>), this would be a noninformative approach that would essentially be akin to maximum likelihood estimation. One might wonder at this point why we wouldn’t just use vague priors all the time and not worry about overly influencing the analysis by the choice of prior.</p>
<p>As an example, let’s assume a uniform distribution <span class="math inline">\((-\infty,\infty)\)</span> for some parameter <span class="math inline">\(\theta\)</span>. Without bounds, this prior is <em>improper</em>, i.e. the probability distribution does not integrate to 1. While the posterior distribution may be proper, it is left the the researcher to determine this. One also has to choose a suitable range, something which may not be easy to ascertain. In addition, the distribution may not be uniform on some transformation of the parameter, say <span class="math inline">\(\theta^2\)</span>. A <em>Jeffreys’ prior</em> could be used to overcome this particular issue, but is more difficult for multiparameter settings.</p>
<p>In general there are several issues with using a noninformative or reference prior. For many models there may be no clear choice of what to use. In any case, if the data are sufficient, the prior won’t matter, so establishing some reference to be used automatically isn’t exactly in keeping with Bayesian thinking. Furthermore, if you had clear prior information from previous research, one should use it. Furthermore, such choices can still have unintended effects on the results. In reality, any prior could be said to be <span class="emph">weakly informative</span>.</p>
<p>So instead of being completely ignorant, we can choose instead to be mostly ignorant, vague but not too vague. As an example, consider our earlier <a href="02_example.html#prior-likelihood-posterior-distributions">binomial distribution example</a>. Perhaps a reasonable guess as to the probability of making a penalty was .75. With that as a basis, we could choose a Beta distribution that would have roughly 80% of its probability between .6 and .9. We know that lower values for the parameters of a beta distribution represent a less informed state of mind, and the mean of the distribution is A/(A+B), so we could just fiddle with some values to see what we can turn up. The following code suggests a <span class="math inline">\(\mathcal{B}(9,3)\)</span> would probably be our best bet. One can examine the distribution to the right. <span class="marginnote"><span class="imgbigger"><img src="img/betaDistr9and3.svg" style="display:block; margin: 0 auto;" width=50%></span></span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">diff</span>(<span class="kw">pbeta</span>(<span class="kw">c</span>(.<span class="dv">6</span>, .<span class="dv">9</span>), <span class="dv">3</span>, <span class="dv">1</span>))
<span class="kw">diff</span>(<span class="kw">pbeta</span>(<span class="kw">c</span>(.<span class="dv">6</span>, .<span class="dv">9</span>), <span class="dv">8</span>, <span class="dv">3</span>))
<span class="kw">diff</span>(<span class="kw">pbeta</span>(<span class="kw">c</span>(.<span class="dv">6</span>, .<span class="dv">9</span>), <span class="dv">9</span>, <span class="dv">3</span>))</code></pre></div>
<pre><code>[1] 0.513
[1] 0.7625194
[1] 0.7915213</code></pre>
<p>With our regression model we were dealing with standardized predictors, so even choosing a <span class="math inline">\(\mathcal{N}(0, 10)\)</span> might be overly vague, though it would be near flat from -1 to 1. The nice part about setting the prior mean on zero is that it has a regularizing effect that can help avoid overfitting with smaller samples.</p>
<p>Thus weakly informative priors can be based on perfectly reasonable settings, and this probably makes more sense than claiming complete ignorance. Just some casual thought in many settings will often reveal that one isn’t completely ignorant. Furthermore if we have clear prior information, in the form of prior research for example, we can then use <span class="emph">informative</span> priors based on those results. This again would be preferable to a completely noninformative approach.</p>
</div>
<div id="conjugacy" class="section level3">
<h3>Conjugacy</h3>
<p>Another consideration in the choice of prior is <span class="emph">conjugacy</span>. Consider using the beta distribution as a prior for the binomial setting as we have done previously. It turns out that using a <span class="math inline">\(\beta(\mathcal{A}, \mathcal{B})\)</span> results in the following posterior:</p>
<p><span class="math display">\[p(\theta|y, n) \propto \beta(y+\mathcal{A}, n-y+\mathcal{B})\]</span></p>
<p>Thus the posterior has the same parametric form as the prior, i.e. the beta distribution is <em>congugate</em> for the binomial likelihood. In this sense, the prior has the interpretation as providing additional data points. In our regression model, the conjugate setting uses a normal distribution for the predictor coefficients and an inverse gamma for <span class="math inline">\(\sigma^2\)</span>. In the case of exponential family distributions of generalized linear models, there are also natural conjugate prior distributions.</p>
<p>While there can be practical advantages to using a conjugate prior, it is not required, and for many more complex models, may not even be possible. However it might help to consider a known conjugate prior as a starting point if nothing else.</p>
</div>
<div id="sensitivity-analysis-revisited" class="section level3">
<h3>Sensitivity Analysis Revisited</h3>
<p>As a reminder, we pointed out in the <a href="04_diagnostics.html#sensitivity-analysis">sensitivity analysis</a> section of the discussion on model checking, one may perform checks on settings for the model to see if changes to them results in gross changes of inference from the posterior. Part of that check should include the choice of prior, whether different parameter values for the same distribution, or different distributions altogether. Doing such a check will give you more confidence in the final selection.</p>
</div>
<div id="summary-1" class="section level3">
<h3>Summary</h3>
<p><span class="marginnote">The BUGS book has many examples for a wide variety of applications. The <a href="https://github.com/stan-dev/example-models/wiki">Stan github page</a> has Stan examples for each of those BUGS examples and many more.</span> It will not take long with a couple Bayesian texts or research articles that employ Bayesian methods to get a feel for how to go about choosing priors. One should also remember that in the face of a lot of data, the likelihood will overwhelm the prior, rendering the choice effectively moot. While the choice might be considered subjective in some respects, it is not arbitrary, and there are standard choices for common models and guidelines for more complex ones to help the researcher in their choice.</p>
</div>
</div>
<div id="sampling-procedure" class="section level2">
<h2>Sampling Procedure</h2>
<p>There are many ways in which one might sample from the posterior. Bayesian analysis is highly flexible and can solve a great many statistical models in theory. In practice things can be more difficult. As more complex models are attempted, new approaches are undertaken to deal with the problems in estimation that inevitably arise. In an attempt to dissolve at least some of the mystery, a brief description follows.</p>
<div id="metropolis" class="section level3">
<h3>Metropolis</h3>
<p>We have mentioned that BUGS and JAGS use <span class="emph">Gibbs sampling</span>, which is a special case of the <span class="emph">Metropolis-Hastings</span> (MH) algorithm<label for="tufte-sn-30" class="margin-toggle sidenote-number">30</label><input type="checkbox" id="tufte-sn-30" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">30</span> Originally developed in physics in the 50s, it eventually made its way across to other fields.</span>, a very general approach encompassing a wide variety of techniques. The Metropolis algorithm can be briefly described in the following steps:</p>
<ol style="list-style-type: decimal">
<li>Start with initial values for the parameters <span class="math inline">\(\theta^0\)</span></li>
</ol>
<p>For <span class="math inline">\(t=1,2...N_{sim}:\)</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Sample from some proposal distribution a potential candidate <span class="math inline">\(\theta^*\)</span>, given <span class="math inline">\(\theta^{t-1}\)</span></li>
<li>Calculate the ratio <span class="math inline">\(r\)</span> of the posterior densities <span class="math inline">\(\frac{p(\theta^*|y)}{p(\theta^{t-1}|y)}\)</span><label for="tufte-sn-31" class="margin-toggle sidenote-number">31</label><input type="checkbox" id="tufte-sn-31" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">31</span> In practice we can take the difference in the log values.</span></li>
<li>Set <span class="math inline">\(\theta^t = \theta^*\)</span> with probability <span class="math inline">\(\min(r, 1)\)</span>, else <span class="math inline">\(\theta^t = \theta^{t-1}\)</span></li>
</ol>
<p>Conceptually, if the proposal increases the posterior density, <span class="math inline">\(\theta^t = \theta^*\)</span>. If it decreases the proposal density, set <span class="math inline">\(\theta^t = \theta^*\)</span> with probability <span class="math inline">\(r\)</span>, else it is <span class="math inline">\(\theta^{t-1}\)</span>. The MH algorithm generalizes the Metropolis to use asymmetric proposal distributions and uses an <span class="math inline">\(r\)</span> to correct for asymmetry<label for="tufte-sn-32" class="margin-toggle sidenote-number">32</label><input type="checkbox" id="tufte-sn-32" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">32</span> Given a proposal/jumping distribution <span class="math inline">\(\mathcal{J}_t\)</span>, <br> <span class="math inline">\(r=\frac{p(\theta^*|y)/\mathcal{J}_t(\theta^*|\theta^{t-1})} {p(\theta^{t-1}|y)/\mathcal{J}_t(\theta^{t-1}|\theta^*)}\)</span></span>.</p>
<p>Let’s look at this in generic/pseudo R code for additional clarity:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">nsim =<span class="st"> </span>numberSimulatedDraws
theta0 =<span class="st"> </span>initValue
theta =<span class="st"> </span><span class="kw">c</span>(theta0, <span class="kw">rep</span>(<span class="ot">NA</span>, nsim))

for (t in <span class="dv">2</span>:nsim){
  thetaStar =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1</span>, theta[-<span class="dv">1</span>], sd)
  u =<span class="st"> </span><span class="kw">runif</span>(<span class="dv">1</span>)
  r =<span class="st"> </span><span class="kw">exp</span>(logPosterior_thetaStar -<span class="st"> </span>logPosterior_theta0)
  theta[t] =<span class="st"> </span><span class="kw">ifelse</span>(u&lt;=r, thetaStar, theta[-<span class="dv">1</span>])
}</code></pre></div>
<p>One can see the <a href="#MHexample">Metropolis-Hastings Example</a> to see the Metropolis algorithm applied to our regression problem.</p>
</div>
<div id="gibbs" class="section level3">
<h3>Gibbs</h3>
<p>The Gibbs sampler takes an alternating approach for multiparameter problems, sampling one parameter given the values of the others, and thus reducing a potentially high dimensional problem to lower dimensional conditional densities. We can describe its steps generally as follows.</p>
<p>Start with initial values for some ordering of the parameters <span class="math inline">\(\theta_1^0, \theta_2^0,..., \theta_p^0\)</span></p>
<p>For <span class="math inline">\(t=1,2..., N_{sim}:\)</span></p>
<p>At iteration <span class="math inline">\(t\)</span>, for <span class="math inline">\(p=1,2..., P:\)</span></p>
<ul>
<li><ol style="list-style-type: decimal">
<li><span class="math inline">\(\theta_1^t \sim p(\theta_1^t | \theta_2^{t-1}, \theta_3^{t-1}, ..., \theta_p^{t-1})\)</span></li>
</ol></li>
<li><ol start="2" style="list-style-type: decimal">
<li>Generate <span class="math inline">\(\theta_2^t \sim p(\theta_2^t | \theta_1^{t}, \theta_3^{t-1}, ..., \theta_p^{t-1})\)</span></li>
</ol></li>
<li><p>     <span class="math inline">\(\vdots\)</span></p></li>
<li><ol start="16" style="list-style-type: lower-alpha">
<li>Generate <span class="math inline">\(\theta_p^t \sim p(\theta_p^t | \theta_1^{t}, \theta_2^{t}, ..., \theta_{p-1}^{t})\)</span></li>
</ol></li>
</ul>
<p>Again, some generic code may provide another way to understand it:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">for (t in <span class="dv">1</span>:nsim){
  for (p in <span class="dv">1</span>:P){
    thetaNew[p] =<span class="st"> </span><span class="kw">rDistribution</span>(<span class="dv">1</span>, theta[t,-p])
  }
  theta[t,] =<span class="st"> </span>thetaNew
}</code></pre></div>
</div>
<div id="hamiltonian-monte-carlo" class="section level3">
<h3>Hamiltonian Monte Carlo</h3>
<p>Stan uses <span class="emph">Hamiltonian Monte Carlo</span>, another variant of MH. It takes the parameters <span class="math inline">\(\theta\)</span> as collectively denoting the position of a particle in some space with momentum <span class="math inline">\(\phi\)</span> (of same dimension as <span class="math inline">\(\theta\)</span>). Both <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\phi\)</span> are updated at each Metropolis step and jointly estimated, though we are only interested in <span class="math inline">\(\theta\)</span>. We can describe the basic steps as follows.</p>
<ol style="list-style-type: decimal">
<li>At iteration <span class="math inline">\(t\)</span>, take a random draw of momentum <span class="math inline">\(\phi\)</span> from its posterior distribution</li>
<li>Update the position vector <span class="math inline">\(\theta\)</span> given current momentum, update <span class="math inline">\(\phi\)</span> given the gradient of <span class="math inline">\(\theta\)</span></li>
<li>Calculate <span class="math inline">\(r = \frac{p(\theta^*|y)p(\phi^*)}{p(\theta^{t-1})p(\phi^{t-1})}\)</span></li>
<li>Set <span class="math inline">\(\theta^t = \theta^*\)</span> with probability <span class="math inline">\(min(r, 1)\)</span>, else <span class="math inline">\(\theta^t = \theta^{t-1}\)</span></li>
</ol>
<p>The overall process allows it to move quite rapidly through the parameter space, and it can work well where other approaches such as Gibbs might be very slow. An example using HMC on the regression model data can be found in the <a href="#HMCexample">Hamiltonian Monte Carlo Example</a><label for="sn-demo" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-demo" class="margin-toggle"/><span class="sidenote">See this entry at David Mimno’s blog for a <a href="http://www.mimno.org/articles/hmc/">visualization of the process</a>.</span></p>
</div>
<div id="other-variations-and-approximate-methods" class="section level3">
<h3>Other Variations and Approximate Methods</h3>
<p>Within these MH approaches there are variations such as slice sampling, reversible jump, particle filtering, etc. Also, one can reparameterize the model to help overcome some convergence issues if applicable. In addition, there exist many approximate methods such as Variational Bayes, INLA, Approximate Bayesian Computation, etc. The main thing is just to be familiar with what’s out there in case it might be useful. Any particular method might be particularly well suited to certain models (e.g. INLA for spatial regression models), those that are notably complex, or they may just be convenient for a particular case.</p>
</div>
</div>
<div id="number-of-draws-thinning-warm-up" class="section level2">
<h2>Number of draws, thinning, warm-up</h2>
<p>Whatever program we use, the typical inputs that will need to be set regard the number of simulated draws from the posterior, the number of warm-up draws, and the amount of thinning. Only the draws that remain after warm-up and thinning will be used for inference. However, there certainly is no default that would work from one situation to the next.</p>
<p>Recall that we are looking for convergence to a distribution, and this isn’t determined by the number of draws alone. The fact is that one only needs a few draws for accurate inference. Even something as low as <span class="math inline">\(n_{\textrm{eff}}\)</span> of 10 for each chain would actually be fine assuming everything else seemed in order, though typically we want more than that so that our values don’t bounce around from one model run to the next. To feel confident about convergence, i.e. get <span class="math inline">\(\hat R\)</span> of around 1, plots looking right, etc., we will usually want in the thousands for the number of total draws. We might need quite a few more for increasing model complexity.</p>
<p>A conservative approach to the number of warm-up draws is half the number of runs, but this is fairly arbitrary. Thinning isn’t specifically necessary for inference if approximate convergence is achieved, but is useful with increasing model complexity to reduce autocorrelation among the estimates.</p>
<p>For myself, I typically run models such that the results are based on roughly <span class="math inline">\(n_{\textrm{eff}} = 1000\)</span> estimates per chain, simply because 1000 is a nice round number and is enough to make graphical display nice. For a regression model as we have been running, that could be setting the number of simulations at 12000, the warm-up at 2000, and thinning at 10. Other models might make due with 100000, 50000, 50 respectively. You may just need to feel things out for yourself.</p>
</div>
<div id="model-complexity" class="section level2">
<h2>Model Complexity</h2>
<p>One of the great things about the Bayesian approach is its ability to handle extremely complex models involving lots of parameters. In addition, it will often work better (or at all) in simpler settings where the data under consideration are problematic (e.g. collinearity, separation in the logistic regression setting). While it can be quite an undertaking to set things correctly and debug, re-run etc. and generally go through the trial and error process typically associated with highly complex models, it’s definitely nice to know that you can. It will take some work, but you will also learn a great deal along the way. Furthermore, there are typically tips and tricks that can potentially help just about any model run a little more smoothly.</p>

</div>
</div>
<p style="text-align: center;">
<a href="05_enhancements.html"><button class="btn btn-default">Previous</button></a>
<a href="1000_Conclusion.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>



</body>
</html>
