---
title: <span style="color:#0085A1; font-size:5rem">Generalized Additive Models</span>
author: |
  | <a href="http://mclark--.github.io/"><span style="font-size:2rem">Michael Clark</span></a>
  | <span style="color:#00274c">Statistician Lead
  | Consulting for Statistics, Computing and Analytics Research
  | Advanced Research Computing </span>
date: '`r Sys.Date()`'
output:
  html_document:
    css: tufte-css-master/tufte.css
    highlight: pygments
    keep_md: no
    theme: cosmo
    toc: yes
    toc_float: yes
    # code_folding: show
  pdf_document:
    highlight: pygments
    toc: yes
always_allow_html: yes
---


#<a name='OtherIssues'>Other Issues</a>

##<a name='Estimation'>Estimation</a>

<span class="newthought">As noted previously</span>, estimation of GAMs in the mgcv package is conducted via a penalized likelihood approach. Conceptually this amounts to fitting the following model

$$g(\mu) = X\beta + f(x_1) + f(x_2) ... f(x_p)$$

But note that each smooth has its own model matrix made up of the bases. So for each smooth covariate we have:

$$f_j = \tilde{X}_j \tilde{\beta}_j$$

Given a matrix of coefficients $S$, we can more formally note a penalized likelihood function:

$$l_p(\beta)=\displaystyle l(\beta) - \frac{1}{2}\sum_j\lambda_j \beta^\mathrm{T} S_j\beta$$

where $l(\beta)$ is the usual GLM likelihood function, and $\lambda_j$ are the smoothing parameters.  The part of the function including $\lambda$ penalizes curvature in the function, where $\lambda$  establishes a trade-off between the goodness of fit and the smoothness, and such an approach will allow for less overfitting<label for="sn-demo" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-demo" class="margin-toggle"/><span class="sidenote">$\lambda\rightarrow\infty$ would result in a straight line estimate for $f_j$, while $\lambda = 0$ would allow any $f$ that interpolates the data (p. 128, @wood_generalized_2006)</span>.  Technically we could specify the smoothing parameters explicitly, and the \hyperref[code:Penalized_Estimation_Example]{appendix} has some 'by-hand' code taken directly from @wood_generalized_2006 with only slight modifications, where the smoothing parameters are chosen and compared<label for="sn-demo" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-demo" class="margin-toggle"/><span class="sidenote">And we would have to choose in order for the penalized maximum likelihood to work.</span>.

Smoothing parameters however are in fact estimated, and this brings us back to the cross-validation procedure mentioned before.  Smoothing parameters are selected which minimize the GCV score by default, though one has other options.  Note that there are other approaches to estimation such as backfitting, generalized smoothing splines and Bayesian.


###<a name='Shrinkage'>Shrinkage & Variable Selection</a>

Some smooths are such that no matter the smoothing parameter, there will always be non-zero coefficients.  An extra penalty may be added such that if the smoothing parameter is large enough, the coefficients will shrink to zero, and some smoothing bases will have such alternative approaches available<label for="sn-demo" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-demo" class="margin-toggle"/><span class="sidenote">See also, the `select` argument to the <span class="func">gam</span> function. Also, in version 1.7-19, <span class="func">summary.gam</span> and <span class="func">anova.gam</span> had changes made to improve the p-value computation in penalized situations.</span>.  In this manner one can assess whether a predictor is adding anything to the model, i.e. if it's effective degrees of freedom is near zero, and perhaps use the approach as a variable selection technique.


###<a name='EDF'>Effective degrees of freedom again</a>

If we define a matrix $F$ that maps the unpenalized estimates of $\beta$ to the penalized estimates such that

$$F = (X^T X + S)^{-1} X^T X$$

and note

$$\tilde{\beta} = (X^T X)^{-1} X^T y$$
$$\hat{\beta} = F\tilde{\beta}$$

the diagonal elements of $F$ are where the effective degrees of freedom for each covariate come from.  


##<a name='smoothFunc'>Choice of Smoothing Function</a>

A number of smooths are available with the <span class="pack">mgcv</span> package, and one can learn more via the help file for <span class="func">smooth.terms</span>. In our models we have used cubic regression splines and thin plate regression splines (TPRS), the latter being the default for a GAM in this package.  As a brief summary, TPRS work well in general in terms of performance and otherwise has some particular advantages, and has a shrinkage alternative available.  One should still feel free to play around, particularly when dealing with multiple smooths, where the tensor product smooths would be better for covariates of different scales.


##<a name='diagnostics'>Diagnostics \& Choice of Basis Dimension</a>
We have some built-in abilities to examine whether there are any particular issues, and we can try it with our second GAM model.

```{r gam_check, echo=3, eval=1:2}
par(bg='transparent')
gam.check(mod_gam2, bty='n')
gam.check(mod_gam2)
```

The plots are of the sort we're used to from a typical regression setting, though it's perhaps a bit difficult to make any grand conclusion based on such a small data set. <span class="marginnote">One can inspect the quantile-quantile plot directly with the <span class="func">qq.gam</span></span> function. The printed output on the other hand contains unfamiliar information, but is largely concerned with over-smoothing, and so has tests of whether the basis dimension for a smooth is too low.  The p-values are based on simulation, so I bumped up the number with the additional argument. Guidelines are given in the output itself, and at least in this case it does not look like we have an issue.  However, if there were a potential problem, it is suggested to double $k$<label for="sn-demo" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-demo" class="margin-toggle"/><span class="sidenote">$k$ can be set as an argument to `s(var1, k=?)`.</span> and refit, and if the effective degrees of freedom increases quite a bit you would probably want to go with the updated model<label for="sn-demo" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-demo" class="margin-toggle"/><span class="sidenote">I actually did this for Health, which is the only one of the predictors that could be questioned, and there was no change at all; it still reduced to a linear effect.</span>.  Given the penalization process, the exact choice of $k$ isn't too big of a deal, but the defaults are arbitrary.  You want to set it large enough to get at the true effect as best as possible, but in some cases computational efficiency will also be of concern.  The help on the function <span class="func">choose.k</span> provides another approach to examining $k$ based on the residuals from the model under consideration, and provides other useful information.


##<a name='prediction'>Prediction</a>

A previous example used the predict function on the data used to fit the model to obtain fitted values on the response scale.  Typically we'd use this on new data.  I do not cover it, because the functionality is the same as the <span class="func">predict.glm</span> function in base R, and one can just refer to that.  It is worth noting that there is an option, `type='lpmatrix'`, which will return the actual model matrix by which the coefficients must be pre-multiplied to get the values of the linear predictor at the supplied covariate values.  This can be particularly useful towards opening the \hyperref[section:blackbox]{black box} as one learns the technique.


##<a name='modComparisonRevisited'>Model Comparison Revisited</a>

We have talked about automated smoothing parameter and term selection, and in general potential models are selected based on estimation of the smoothing parameter.  Using an extra penalty to allow coefficients to tend toward zero with the argument `select=TRUE` is an automatic way to go about it, where some terms could effectively drop out. Otherwise we could compare models GCV/AIC scores<label for="sn-demo" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-demo" class="margin-toggle"/><span class="sidenote">GCV scores are not useful for comparing fits of different families; AIC is still ok though.</span>, and in general either of these would be viable approaches. Consider the following comparison:


```{r mod_comparison}
mod_1d = gam(Overall ~ s(Income) + s(Edu), data=d)
mod_2d = gam(Overall ~ te(Income,Edu, bs="tp"), data=d)
AIC(mod_1d, mod_2d)
```

In some cases we might prefer to be explicit in comparing models with and without particular terms, and we can go about comparing models as we would with a typical GLM analysis of deviance.  We have demonstrated this previously using the <span class="func">anova.gam</span> function, where we compared linear fits to a model with an additional smooth function.  While we could construct a scenario that is identical to the GLM situation for a statistical comparison, it should be noted that in the usual situation the test is actually an approximation, though it should be close enough when it is appropriate in the first place.  The following provides an example that would nest the main effects of Income and Education within the product smooth, i.e. sets their basis dimension and smoothing function to the defaults employed by the te smooth.

```{r anova_nest}
mod_A = gam(Overall ~ s(Income, bs="cr", k=5) + s(Edu, bs="cr", k=5), data=d)
mod_B = gam(Overall ~ s(Income, bs="cr", k=5) + s(Edu, bs="cr", k=5) + te(Income, Edu), data=d)

anova(mod_A,mod_B, test="Chi")
```

Again though, we could have just used the summary output from the second model.

Instances where such an approach does not appear to be appropriate within the context of the <span class="mgcv"></span> package are when terms are able to be penalized to zero; in such a case p-values will be much too low. In addition, when comparing GAMs, sometimes the nesting of models would not be so clear when there are multiple smooths involved, and additional steps may need to be taken to make sure they are nested. We must make sure that each smooth term in the null model has no more effective degrees of freedom than the same term in the alternative, otherwise it's possible that the model with more terms can have lower effective degrees of freedom but better fit, rendering the test nonsensical.  @wood_generalized_2006 suggests that if such model comparison is the ultimate goal an unpenalized approach<label for="sn-demo" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-demo" class="margin-toggle"/><span class="sidenote">This can be achieved with the argument `s(..., fx=T)`, although now one has to worry more about the k value used, as very high k will lead to low power.</span> would be best to have much confidence in the p-values<label for="sn-demo" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-demo" class="margin-toggle"/><span class="sidenote">One might also examine the <span class="gss"></span> package for anova based approach to generalized smoothing splines.</span>.

