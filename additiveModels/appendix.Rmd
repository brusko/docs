---
title: <span style="color:#0085A1; font-size:5rem">Generalized Additive Models</span>
author: |
  | <a href="http://mclark--.github.io/"><span style="font-size:2rem">Michael Clark</span></a>
  | <span style="color:#00274c">Statistician Lead
  | Consulting for Statistics, Computing and Analytics Research
  | Advanced Research Computing </span>
date: '`r Sys.Date()`'
output:
  html_document:
    css: tufte-css-master/tufte.css
    highlight: pygments
    keep_md: no
    theme: cosmo
    toc: yes
    toc_float: yes
bibliography: refs.bib
nocite: | 
  @wood_generalized_2006, @venables_modern_2002, @rasmussen_gaussian_2006, @hardin_generalized_2012, 
  @rigby_generalized_2005, @hastie_generalized_1990, @fox_multiple_2000, @fox_nonparametric_2000,
  @breiman_statistical_2001, @bybee_pisa_2009, @hastie_elements_2009, @ruppert_semiparametric_2003,
  @wasserman_all_2006, @fahrmeir2013regression, @friedman2000additive
---
#<a name='appendix'>Appendix</a>

##<a name='packages'>R packages</a>
<span class="newthought">The following is</span> a non-exhaustive list of R packages which contain GAM functionality. Each is linked to the CRAN page for the package.  Note also that several build upon the <span class="pack">mgcv</span> package used for this document.

[brms](http://cran.r-project.org/web/packages/brms/) Allows for Bayesian GAMs via the Stan modeling language (very new implementation).

[CausalGAM](http://cran.r-project.org/web/packages/CausalGAM/) This package implements various estimators for average treatment effects. 

[COZIGAM](http://cran.r-project.org/web/packages/COZIGAM/) Constrained and Unconstrained Zero-Inflated Generalized Additive Models.

[CoxBoost](http://cran.r-project.org/web/packages/CoxBoost/) This package provides routines for fitting Cox models. See also <span class="func">cph</span> in rms package for nonlinear approaches in the survival context.

[gam](http://cran.r-project.org/web/packages/gam/) Functions for fitting and working with generalized additive models.  

[GAMBoost](http://cran.r-project.org/web/packages/GAMBoost/): This package provides routines for fitting generalized linear and and generalized additive models by likelihood based boosting.

[gamboostLSS](http://cran.r-project.org/web/packages/gamboostLSS/): Boosting models for fitting generalized additive models for location, shape and scale (gamLSS models). 

[GAMens](http://cran.r-project.org/web/packages/GAMens/): This package implements the GAMbag, GAMrsm and GAMens ensemble classifiers for binary classification.

[gamlss](http://cran.r-project.org/web/packages/gamlss/): Generalized additive models for location, shape, and scale. 

[gamm4](http://cran.r-project.org/web/packages/gamm4/): Fit generalized additive mixed models via a version of mgcv's gamm function.  

[gammSlice](http://cran.r-project.org/web/packages/gammSlice/): Bayesian fitting and inference for generalized additive mixed models.

[GMMBoost](http://cran.r-project.org/web/packages/GMMBoost/): Likelihood-based Boosting for Generalized mixed models.

[gss](http://cran.r-project.org/web/packages/gss/):  A comprehensive package for structural multivariate function estimation using smoothing splines.

[mboost](http://cran.r-project.org/web/packages/mboost/): Model-Based Boosting. 

[mgcv](http://cran.r-project.org/web/packages/mgcv/): Routines for GAMs and other generalized ridge regression with multiple smoothing parameter selection by GCV, REML or UBRE/AIC. Also GAMMs. 

[VGAM](http://cran.r-project.org/web/packages/VGAM/): Vector generalized linear and additive models, and associated models.



##<a name='Penalized_Estimation_Example'>Penalized Estimation Example</a>

Initial data set up and functions.

```{r Penalized_Estimation_Example}
############################
### Wood by-hand example ###
############################

size = c(1.42,1.58,1.78,1.99,1.99,1.99,2.13,2.13,2.13,
         2.32,2.32,2.32,2.32,2.32,2.43,2.43,2.78,2.98,2.98)
wear = c(4.0,4.2,2.5,2.6,2.8,2.4,3.2,2.4,2.6,4.8,2.9,
         3.8,3.0,2.7,3.1,3.3,3.0,2.8,1.7)
x = size - min(size); x = x/max(x)
d = data.frame(wear, x)

#cubic spline function
rk <- function(x,z) {
  ((z-0.5)^2 - 1/12)*((x-0.5)^2 - 1/12)/4 -
    ((abs(x-z)-0.5)^4-(abs(x-z)-0.5)^2/2 + 7/240) / 24
}

spl.X <- function(x,knots){
  q <- length(knots) + 2                # number of parameters
  n <- length(x)                        # number of observations
  X <- matrix(1, n, q)                  # initialized model matrix
  X[,2] <- x                            # set second column to x
  X[,3:q] <- outer(x, knots, FUN = rk)  # remaining to cubic spline
  X
}

spl.S <- function(knots) {
  q = length(knots) + 2
  S = matrix(0, q, q)                           # initialize matrix
  S[3:q, 3:q] = outer(knots, knots, FUN=rk)     # fill in non-zero part
  S
}

#matrix square root function
mat.sqrt <- function(S){
  d = eigen(S, symmetric=T)
  rS = d$vectors %*% diag(d$values^.5) %*% t(d$vectors)
  rS
}

#the fitting function
prs.fit <- function(y, x, knots, lambda) {
  q = length(knots) + 2       # dimension of basis
  n = length(x)               # number of observations
  Xa = rbind(spl.X(x, knots), mat.sqrt(spl.S(knots))*sqrt(lambda))  # augmented model matrix
  y[(n+1):(n+q)] = 0          # augment the data vector
  lm(y ~ Xa - 1)              # fit and return penalized regression spline
}
```

Example 1.

```{r Penalized_Estimation_Example_Example1, dev.args = list(bg = 'transparent')}
knots = 1:4/5
X = spl.X(x, knots)           # generate model matrix
mod.1 = lm(wear ~ X - 1)      # fit model
xp <- 0:100/100               # x values for prediction
Xp <- spl.X(xp, knots)        # prediction matrix

# plot
library(ggplot2)
ggplot(aes(x=x, y=wear), data=data.frame(x,wear))+
  geom_point(color="#FF8000") +
  geom_line(aes(x=xp, y=Xp%*%coef(mod.1)), data=data.frame(xp,Xp), color="#2957FF") +
  theme_trueMinimal() +
  theme(plot.background=element_blank(),
        panel.background=element_blank())
ggplotly()
```


Example 2.


```{r Penalized_Estimation_Example_Example12, dev.args = list(bg = 'transparent')}
knots = 1:7/8

d2 = data.frame(x=xp)

for (i in c(.1, .01, .001, .0001, .00001, .000001)) {
  mod.2 = prs.fit(y=wear, x=x, knots=knots, lambda=i)   # fit penalized regression 
                                                        # spline choosing lambda
  Xp = spl.X(xp,knots)                                  # matrix to map parameters to fitted values at xp
  d2[,paste('lambda = ',i, sep="")] = Xp%*%coef(mod.2)
}

### plot
library(ggplot2); library(tidyr)
d3 = gather(d2, key=variable, value=value, factor_key=T, -x)

ggplot(aes(x=x, y=wear), data=d) +
  geom_point(col='#FF8000') +
  geom_line(aes(x=x,y=value), col="#2957FF", data=d3) +
  facet_wrap(~variable) +
  theme_trueMinimal() +
  theme(plot.background=element_blank(),
        panel.background=element_blank())
ggplotly()
```


##<a name='basisfunc'>Basis functions for a cubic spline</a>

We can take the same approach as with the polynomial example, and plot the basis functions. First let's look at the model matrix.

```{r csbs, echo=FALSE, eval=FALSE}
detach(package:MASS)
Income = select(d, Overall, Income) %>% na.omit()  %>% select(Income) %>% .[,1]
Overall = select(d, Overall, Income) %>% na.omit() %>% select(Overall) %>% .[,1]
knots = seq(.4, 1, length=10); knots = knots[-length(knots)]  # don't need the last value
l = 1
bs = sapply(1:length(knots), function(k) ifelse(Income >= knots[k], (Income-knots[k])^l, 0)) %>% 
  data.frame() %>% 
  arrange(Income)

head(bs)
```

Note that we have many more columns than we normally would fit with a polynomial regression.  We'll see how this complexity is deal with later.  The first column represents our intercept as it does in every other standard model matrix. The second represents the linear form of Income, though it is scaled differently (i.e. the correlation is perfect).  If we plot this against Income, it doesn't look like much.

```{r csbsPlot, echo=FALSE, eval=FALSE}
library(tidyr)
bs = data.frame(int=1, bs)
d2 = data.frame(Income, bs) %>% 
  gather(key=bs, value=bsfunc, -Income)


# plot_ly(data=d2, x=Income, y=Overall, width='auto', mode='markers', showlegend=F,
#         marker=list(color='black', opacity=.2)) %>% 
#   add_trace(data=arrange(d2,Income), x=Income, y=bsfunc, group=bs) %>% 
#   theme_plotly()
plot_ly(d2) %>%  add_trace(data=arrange(d2,Income), x=Income, y=bsfunc, group=bs) %>% 
  theme_plotly()
```

However, if we plot Income against the basis multiplied by the estimated coefficients of the model, the data story begins to reveal itself.

```{r csbsScaledPlot, echo=c(2:4,6:7), eval=-1, eval=FALSE}
# bs = as.matrix(data.frame(int=1, bs))
lmMod = lm(Overall~.-1, bs)
bscoefs = coef(lmMod)
bsScaled = sweep(bs, 2, bscoefs,`*`)
colnames(bsScaled) = c('int', paste0('X', 1:9))
head(bsScaled)
bscoefs

d3 = data.frame(Income, bsScaled) %>% 
  gather(key=bs, value=bsfunc, -Income) %>% 
  arrange(Income)
# %>% 
#   dplyr::filter(bsfunc >= min(Overall) & bsfunc <= max(Overall))

mapply(function(knots, knotf, basis) filter(d3, bs==basis & Income >= knots & Income < knotf), knots, c(knots[-1], 1), unique(d3$bs)[-1], SIMPLIFY=F)

plot_ly(data=d2, x=Income, y=Overall, width='auto', mode='markers', showlegend=F,
        marker=list(color='black', opacity=.2)) %>% 
  add_trace(data=arrange(d3,Income), x=Income, y=bsfunc, group=bs) %>% 
  theme_plotly()
plot_ly(data=filter(d3, bs=='int' & Income<knots[2]), x=Income, y=bsfunc, mode='line', name='Intercept') %>% 
    add_trace(data=filter(d3, bs=='X1' & Income>=knots[1]), x=Income, y=bsfunc, mode='line', name='X1') %>% 
    add_trace(data=filter(d3, bs=='X2' & Income>=knots[2]), x=Income, y=bsfunc, mode='line', name='X2') %>% 
    add_trace(data=filter(d3, bs=='X3' & Income>=knots[3]), x=Income, y=bsfunc, mode='line', name='X3') %>% 
    add_trace(data=filter(d3, bs=='X4' & Income>=knots[4]), x=Income, y=bsfunc, mode='line', name='X4') %>% 
    add_trace(data=filter(d3, bs=='X5' & Income>=knots[5]), x=Income, y=bsfunc, mode='line', name='X5') %>% 
    add_trace(data=filter(d3, bs=='X6' & Income>=knots[6]), x=Income, y=bsfunc, mode='line', name='X6') %>% 
    add_trace(data=filter(d3, bs=='X7' & Income>=knots[7]), x=Income, y=bsfunc, mode='line', name='X7') %>% 
    add_trace(data=rbind(filter(d3, bs=='X8' & Income>=knots[8]),
                         filter(d3, bs=='X8' & Income>=knots[8]),
                         filter(d3, bs=='X8' & Income>=knots[8]),
                         filter(d3, bs=='X8' & Income>=knots[8])), x=Income, y=bsfunc, mode='line', name='X8') %>%
             # stupidly add points automatically when less than 20
# add_trace(data=filter(d3, bs=='X8' & Income>=knots[8]), x=Income, y=bsfunc, mode='line', name='X8') %>%
    add_trace(data=filter(d3, bs=='X9' & Income>=knots[9]), x=Income, y=bsfunc, mode='line', name='X9') %>% 
  theme_plotly()
```

Each trend line represents the fit between knots


