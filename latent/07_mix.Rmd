---
title: "Mixture Models"
author: |
  | Michael Clark
  | Statistician Lead
  | Consulting for Statistics, Computing and Analytics Research
  | <span style="color:'#00274c'">Advanced Research Computing</span>
date: '`r Sys.Date()`'
output:
  html_document:
    css: indexCSS.css
    highlight: tango
    theme: cosmo
    toc: TRUE
    toc_float: TRUE
  pdf_document:
    highlight: pygments
    toc: yes
always_allow_html: yes
---
```{r setupMixture, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message = FALSE, R.options=list(width=120), fig.height=4, fig.width=4, fig.align = 'center')
library(magrittr); library(dplyr)
```



# Mixture Models

Thus far we have understood latent variables as possessing an underlying continuum, i.e. normally distributed with a mean of zero and some variance.  This does not have to be the case, and instead we can posit a categorical variable.  Some approaches you may in fact be already familiar with, as any modeling process under the heading of 'cluster analysis' could be said to deal with latent categorical variables.  The issue is that we may feel that there is some underlying structure to the data that is described as discrete, and based on perhaps multiple variables.  

We will approach this in the way that has been done from statistical and related motivations, rather than the SEM/psychometric approach.  This will make clearer what it is we're dealing with as well as not get bogged down in terminology.  Furthermore, mixture models are typically poorly implemented within SEM, as many of the typical issues can often be magnified.  The goal here as before is clarity of thought over 'being able to run it'.  

A common question in such analysis is *how many clusters*?  There are many, many techniques for answering this question, and not a single one of them even remotely definitive.  On the plus side, the good news is that we already know the answer, because the answer is always 1.  However, that won't stop us from trying to discover more than that, so here we go.


## A Motivating Example
Take a look at the following data. It regards the waiting time between eruptions and the duration of the eruption (both in minutes) for the Old Faithful geyser in Yellowstone National Park, Wyoming, USA.

```{r eval=c(1:2, 4), echo=1:2}
library(ggplot2)
data("faithful")
car::scatterplot(data=faithful, waiting~eruptions)
qplot(data=faithful, x=eruptions, y=waiting, geom = 'point') + lazerhawk::theme_trueMinimal()
```

Take a good look.  This is probably the cleanest separation of clustered data you will likely ever see, and even so there are still data points that might fall into either cluster.

## Create Clustered Data
To get a sense of mixture models, let's actually create some data that might look like the Old Faithful data above. In the following we create something that will look like the eruptions variable in the faithful data. To do so, we draw one random sample from a normal distribution with a mean of 2, and the other with a mean of 4.5, and both get a standard deviation of .25.  The first plot is based on the code below, the second on the actual data.

```{r simFaithful, echo=-(6:7)}
library(ggplot2)
set.seed(1234)
erupt1 = rnorm(150, mean=2, sd=.25)
erupt2 = rnorm(150, mean=4.5, sd=.25)
erupt = sample(c(erupt1, erupt2))
ggplot(aes(x=erupt), data=data.frame(erupt)) + geom_density() + lazerhawk::theme_trueMinimal()
ggplot(aes(x=eruptions), data=faithful) + geom_density() + lazerhawk::theme_trueMinimal()
```

What do we have and what do we see?  The data is a *mixture* of two normals, but we can think of the observations as belonging to a latent class, and each class has its own mean and standard deviation (and is based on a normal, but doesn't have to be).  Each observation has some likelihood, however great or small, of coming from either cluster, and had we really wanted to do more appropriate simulation, we would incorporate that information.

A basic approach for categorical latent variable analysis from a model based perspective[^cluster]:

1. Posit the number of clusters you believe there to be
2. For each observation, estimate those probability of coming from either cluster
3. Assign observations to the most likely class (i.e. the one with the highest probability).

More advanced approaches might include:

- Predicting the latent classes in a manner akin to logistic regression
- Allow your model coefficients to vary based on cluster membership
    - For example, have separate regression models for each class


## Mixture modeling with Old Faithful
The following uses the <span class="pack">flexmix</span>  package and function to estimate a regression model per class.  In this case, our model includes only an intercept, and so is equivalent to estimating the mean and variance of each group.  We posit `k=2` groups.

We can see from the summary about 2/3 are classified to one group. We also get the estimated means and standard deviations for each group.  Note that the group labels are completely arbitrary.

```{r flexmixEruptions, echo=-1}
set.seed(1234)
library(flexmix)
mod = flexmix(eruptions~1,  data=faithful, k = 2)
summary(mod)
head(mod@posterior$scaled, 10) %>% round(4)  # show some estimated probabilities
parameters(mod)    #means and std dev for each group
```


The first plot shows the estimated probabilities for each observation for one of the clusters (with some jitter), which in this case are all around 0 or 1.  Again, you will probably never see anything like this, but clarity is useful here.  The second plot shows the original data with their classification and contours of the density for each group.

```{r echo=F, fig.width=6}
qplot(x=mod@posterior$scaled[,1], y=mod@posterior$scaled[,2]) + 
  geom_jitter(width=.05, height=.05, alpha=.1) + 
  xlab('Posterior Probablity for Group 1') +
  lazerhawk::theme_trueMinimal() 
cluster = factor(mod@cluster)
qplot(data=faithful, x=eruptions, y=waiting, color=cluster) + 
    geom_density2d() +
  lazerhawk::theme_trueMinimal()
```



## SEM and Latent Categorical Variables

Dealing with categorical latent variables can be somewhat problematic. Interpreting one SEM model might be difficult enough, but then one might be allowing parts of it to change depending on which latent class observations belong to, while having to assess the latent class measurement model as well.  It can be difficult to find a clarity of understanding from this process, as one is discovering classes then immediately assuming key differences among these classes they didn't know existed beforehand[^latclass].  In addition, one will need even more data than standard SEM to deal with all the additional parameters that are allowed to vary across the classes.  

Researchers also tend to find classes that represent 'hi-lo' or 'hi-med-lo' groups, which may suggest they should have left the latent construct as a continuous variable. When given the choice to discretize continuous variables in normal settings, it is rare in which the answer is anything but a resounding *no*.  As such, one should think hard about the ultimate goals of such a model.  

### Terminology in SEM

<span class="emph">Latent Class Analysis</span> refers to dealing with categorical latent variables in the context of multivariate categorical data.  For example one might have a series of yes/no questions on a survey, and want to discover categories of responses.

<span class="emph">Latent Profile Analysis</span> refers to dealing with categorical latent variables in the context of multivariate numerical data. 

### Latent Categories vs. Multigroup Analysis

The primary difference between the two is that one grouping structure actually exists in the data, for example, sex, race etc. In that case, a <span class="emph">multigroup analysis</span> would allow for separate SEM models per group.  In the latent categorical variable situation, one must first discover the latent groups. In multigroup analysis, a common goal is to test <span class="emph">measurement invariance</span>, a concept which has several definitions itself.  An example would be to see if the latent structure holds for an American vs. foreign sample, with the same items for the scale provided in the respective languages. This makes a lot of sense from a measurement model perspective and has some obvious use.

If one wants to see a similar situation for a less practically driven model, e.g. to see if an SEM model is the same for males vs. females, this is equivalent to having an interaction with the sex variable for every path in the model.  The same holds for 'subgroup analysis' in typical settings, where you won't find any more than you would by including the interactions of interest with the whole sample, though you will certainly have less data to work with.  In any case, we need a lot of data to compare separate models where parameters are allowed to vary by group vs. a model in which they are fixed, and many simply do not have enough data for this.

### Latent Trajectories

As noted in the growth curve modeling section, these are growth curve models in which intercepts and slopes are allowed to vary across latent groups as well as the clusters.  The flexmix package used previously would allow one to estimate such models from the mixed model perspective, and might be preferred.

### Estimation

If you would like to see the conceptual innards of estimating mixture models using <span class="emph">EM Algorithm</span>, see [this link](https://github.com/mclark--/Miscellaneous-R-Code/tree/master/ModelFitting/EM%20Examples) on my github page.


## R packages used
- <span class="pack">flexmix</span>